{
  "436": {
    "inputs": { "strength": 1, "model": ["441", 0] },
    "class_type": "CFGNorm"
  },
  "437": {
    "inputs": { "vae_name": "qwen_image_vae.safetensors" },
    "class_type": "VAELoader"
  },
  "438": {
    "inputs": {
      "clip_name": "qwen/qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader"
  },
  "439": {
    "inputs": {
      "unet_name": "qwen/qwen_image_edit_2509_fp8_e4m3fn.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader"
  },
  "440": {
    "inputs": {
      "prompt": "",
      "clip": ["438", 0],
      "vae": ["437", 0],
      "image1": ["460", 0],
      "image2": ["448", 0]
    },
    "class_type": "TextEncodeQwenImageEditPlus"
  },
  "441": {
    "inputs": { "shift": 1, "model": ["459", 0] },
    "class_type": "ModelSamplingAuraFlow"
  },
  "442": {
    "inputs": {
      "prompt": "head_swap: start with Picture 1 as the base image, keeping its lighting, environment, and background. remove the head from Picture 1 completely and replace it with the head from Picture 2. ensure the head and body have correct anatomical proportions, and blend the skin tones, shadows, and lighting naturally so the final result appears as one coherent, realistic person.",
      "clip": ["438", 0],
      "vae": ["437", 0],
      "image1": ["460", 0],
      "image2": ["448", 0]
    },
    "class_type": "TextEncodeQwenImageEditPlus"
  },
  "443": {
    "inputs": { "pixels": ["460", 0], "vae": ["437", 0] },
    "class_type": "VAEEncode"
  },
  "444": {
    "inputs": { "samples": ["447", 0], "vae": ["437", 0] },
    "class_type": "VAEDecode"
  },
  "447": {
    "inputs": {
      "seed": 43,
      "steps": 20,
      "cfg": 2,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": ["436", 0],
      "positive": ["442", 0],
      "negative": ["440", 0],
      "latent_image": ["443", 0]
    },
    "class_type": "KSampler"
  },
  "448": {
    "inputs": { "image": "INPUT_HEAD_PLACEHOLDER.png" },
    "class_type": "LoadImage"
  },
  "449": {
    "inputs": { "image": "INPUT_BODY_PLACEHOLDER.png" },
    "class_type": "LoadImage"
  },
  "458": {
    "inputs": { "filename_prefix": "head swap", "images": ["444", 0] },
    "class_type": "SaveImage"
  },
  "459": {
    "inputs": {
      "lora_name": "qwen/bfs_head_v3_qwen_image_edit_2509.safetensors",
      "strength_model": 1,
      "model": ["439", 0]
    },
    "class_type": "LoraLoaderModelOnly"
  },
  "460": {
    "inputs": { "image": ["449", 0] },
    "class_type": "FluxKontextImageScale"
  }
}